# Claude Code Configuration Expertise
# Target: 400-500 lines | Domain: Operational knowledge for .claude/ configuration

overview:
  description: |
    Claude Code configuration—.claude/ directory structure, command patterns,
    hook implementation, expert 4-agent pattern (expertise.yaml + 4 agents),
    and slash command conventions. This expertise enables correct configuration
    of Claude Code projects.
  scope: |
    Covers .claude/ directory organization (agents/, commands/, hooks/, skills/,
    .cache/, data/), command frontmatter schema, hook types with uv, expert
    4-agent pattern (plan/build/improve/question in agents/experts/<domain>/),
    settings configuration, and naming conventions.

    ARCHITECTURAL NOTE [2025-12-26]: Skills are workflow templates (not agents)
    in .claude/skills/. Flat orchestration - /do directly spawns expert agents.
    Coordinators deprecated (nested subagent limitation). Does NOT cover agent
    prompt content (see agent-authoring expert).
  rationale: |
    Correct .claude/ configuration enables tooling, discoverability, and
    maintainability. Poor structure creates fragmentation and breaks tooling.

core_implementation:
  directory_structure:
    .claude/:
      agents/:
        purpose: Agent definitions (general-purpose + experts/)
        experts/<domain>/:
          purpose: 4-agent pattern (plan/build/improve/question + expertise.yaml)
          pattern: 12 domains × 4 agents = 48 agents total
      commands/:
        purpose: Slash commands by category
        do.md: Universal orchestrator - directly spawns expert agents
      skills/:
        purpose: Workflow templates (NOT agents) - guide /do orchestration
      hooks/:
        purpose: Lifecycle hooks (Python with uv)
        utils/: Hook utility modules
      .cache/:
        purpose: Gitignored ephemeral data
        specs/: Spec files from plan agents
        orchestration-traces.jsonl: Task execution traces
      data/:
        purpose: Session and state data (gitignored)
        sessions/: Session metadata JSON
        learnings/: Captured learnings
        temp/: Cross-hook coordination (timing markers)
      logs/:
        purpose: Session logs and analytics (gitignored)
      settings.json:
        purpose: Project-wide config (committed)
      settings.local.json:
        purpose: Local overrides (gitignored)

  key_files:
    - path: .claude/commands/<category>/<name>.md
      purpose: Slash command (frontmatter + prompt)
      invocation: /category:name
    - path: .claude/agents/experts/<domain>/<domain>-{plan,build,improve,question}-agent.md
      purpose: Expert 4-agent pattern with standardized colors
    - path: .claude/agents/experts/<domain>/expertise.yaml
      purpose: Structured domain knowledge (400-600 lines target, 1000 max)
    - path: .claude/hooks/<hook-name>.py
      purpose: Lifecycle hook with uv shebang
    - path: .claude/skills/<workflow>/SKILL.md
      purpose: Workflow template for /do orchestration
    - path: .claude/output-styles/<style-name>.md
      purpose: Reusable output formatting conventions

key_operations:
  create_slash_command:
    when: Adding new command functionality
    approach: |
      1. Create .claude/commands/<category>/<name>.md
      2. Add frontmatter:
         ---
         description: Brief command description (required)
         argument-hint: [param1] [param2 (optional)]
         allowed-tools: Tool, List, Here
         ---
      3. Write prompt (Purpose, Variables, Instructions, Workflow, Report)
      4. Invoked as /category:name
    examples:
      - .claude/commands/book/toc.md → /book:toc
      - .claude/commands/knowledge/capture.md → /knowledge:capture
    pitfalls:
      - what: "CRITICAL - Using colons in frontmatter string values"
        instead: "No colons in description, argument-hint, or any YAML value"
        reason: "Colons break YAML parsing in Claude Code's configuration system. Affects ALL frontmatter, not just agents. [2026-01-17]"

  create_command_with_orchestrator_agent:
    when: Command needs complex coordination beyond single agent capability
    pattern: DEPRECATED - Command + Orchestrator Agent Pairing NO LONGER WORKS
    architecture_issue: |
      CRITICAL CONSTRAINT [2026-02-02]:
      Subagents spawned via Task tool CANNOT use Task/TeammateTool to spawn nested agents.
      This breaks the "command delegates to orchestrator agent" pattern entirely.

      If orchestrator is a subagent, it cannot spawn teams. Architecture is fundamentally broken.
    correct_pattern: |
      For complex orchestration (especially TeammateTool):
      1. Create comprehensive slash command (.claude/commands/<category>/<name>.md)
         - Contains ALL orchestration logic (6 phases: init, classify, spawn, coordinate, wait, report)
         - Frontmatter: allowed-tools includes TeammateTool, SendMessage, Task, etc.
         - 500-700 lines typical for full swarm orchestration
         - No delegation to orchestrator agent (orchestration happens at command level)
      2. No separate orchestrator agent needed or wanted
      3. Update CLAUDE.md with command documentation
    examples:
      - .claude/commands/do.md - 600+ lines, orchestrates plan→build→improve directly
      - .claude/commands/do-teams.md - 650+ lines, orchestrates team coordination directly
    rationale: |
      - TeammateTool operations MUST happen at command level
      - Delegation adds broken indirection layer (subagent can't spawn)
      - Single source of truth for orchestration logic
      - Mirrors Task tool constraint (same limitation)
    benefits:
      - Actually works (subagents can't spawn, commands can)
      - No broken delegation layer
      - Clear single source of truth
      - Comprehensive documentation in one file
    timestamp: "[2026-02-02] Pattern deprecated after discovering Task/TeammateTool spawning constraints"

  implement_hook:
    when: Need to run code on agent lifecycle events
    events: [SessionStart, UserPromptSubmit, PreToolUse, PostToolUse, SubagentStop, PreCompact, Stop]
    approach: |
      1. Create .claude/hooks/<hook-name>.py with uv shebang:
         #!/usr/bin/env -S uv run --script
         # /// script
         # requires-python = ">=3.8"
         # ///
      2. Implement hook function (read JSON from stdin)
      3. Exit 0 (allow) or 2 (block)
      4. Configure in .claude/settings.json hooks object
      5. Use matcher for tool-specific targeting (reduces overhead)
    examples:
      - pre_tool_use_logger.py: Log tool usage, security guards
      - orchestration_trace_logger.py: PostToolUse with Task matcher only

  create_expert_domain:
    when: Adding new expert domain with queryable expertise
    approach: |
      1. Create .claude/agents/experts/<domain>/
      2. Create expertise.yaml (overview, core_implementation, key_operations,
         decision_trees, patterns, best_practices, known_issues)
      3. Create <domain>-plan-agent.md (sonnet, yellow, Read/Glob/Grep/Write, output-style: academic-structured)
      4. Create <domain>-build-agent.md (sonnet, green, Read/Write/Edit/Glob/Grep, +Bash for ops, output-style: practitioner-focused)
      5. Create <domain>-improve-agent.md (sonnet, purple, all tools + Bash for git, output-style: evidence-grounded)
      6. Create <domain>-question-agent.md (haiku, cyan, Read/Glob/Grep only, output-style: concise-reference)
    pattern: 4-agent pattern replaces old 3-file triad (expertise + question + self-improve)
    examples:
      - curriculum: 12th domain, absorbed 2 standalone agents (888 lines total)
      - github: Absorbed github-versioning-agent (383 lines)
    pitfalls:
      - what: "CRITICAL - Using colons in agent description field (e.g., 'Expects: SPEC')"
        instead: "Remove colons from description values (use 'Expects SPEC' not 'Expects: SPEC')"
        reason: "Colons in YAML string values cause Claude Code's agent discovery parser to fail silently. Agents with colons in descriptions will NOT appear in /agents list. [2026-01-17] Root cause confirmed via systematic testing across 38 agents."

  configure_agent_output_style:
    when: Agent needs consistent output formatting
    approach: |
      1. Add output-style field to agent frontmatter (references .claude/output-styles/<name>.md)
      2. Add Output Style documentation to agent's Instructions section
      3. Use standard mappings for 4-agent expert pattern:
         - Question agents: concise-reference (scannable Q&A, haiku model)
         - Plan agents: academic-structured (rigorous specs, standard sections)
         - Build agents: practitioner-focused (action-first, code examples)
         - Improve agents: evidence-grounded (timestamped, git-backed claims)
    examples:
      - file: agents/experts/knowledge/knowledge-question-agent.md
        frontmatter: "output-style: concise-reference"
        instructions: "**Output Style:** Follow .claude/output-styles/concise-reference.md conventions"
    benefits:
      - Consistent output across similar agent types
      - Easier maintenance (update style file, all agents adapt)
      - Clear expectations for agent behavior
    timestamp: 2026-01-21

  configure_settings:
    when: Configuring permissions, hooks, or project behavior
    structure: |
      .claude/settings.json:
      {
        "statusLine": {"type": "command", "command": "..."},
        "permissions": {"allow": ["Read", "Glob"], "deny": []},
        "env": {"VAR": "value"},
        "hooks": {
          "<EventType>": [
            {
              "matcher": {"tool_name": "Task"},  // Optional: tool-specific
              "hooks": [{"type": "command", "command": "...", "timeout": 5000}]
            }
          ]
        }
      }
    notes: |
      - Local overrides in settings.local.json (gitignored)
      - Matcher enables tool-specific hooks (e.g., PostToolUse only for Task)
      - Valid JSON (no trailing commas)

decision_trees:
  command_vs_agent_vs_skill:
    question: What am I creating?
    options:
      - if: User-invoked task with fixed workflow
        then: Slash command (.claude/commands/)
      - if: Model-invoked sub-agent for delegation
        then: Agent (.claude/agents/)
      - if: Workflow template to guide /do orchestration
        then: Skill (.claude/skills/) - NOT an agent
      - if: Domain expertise with plan/build/improve/question
        then: Expert domain (.claude/agents/experts/<domain>/)
      - if: Command needs complex coordination (messaging, parallel, patterns)
        then: Command + Orchestrator Agent pair (do-teams pattern)

  simple_vs_orchestrator_command:
    question: Is this a simple command or does it need orchestration?
    options:
      - if: Single sequential task, deterministic workflow
        then: Simple command (command file only)
        example: "/book:toc - regenerate table of contents"
      - if: Complex coordination, multi-pattern support, rich messaging
        then: Command + Orchestrator Agent pairing
        example: "/do-teams - parallel coordination with leader-worker/council/pipeline patterns"
      - reasoning: |
          Orchestrator agents enable:
          - Multiple coordination patterns (lead-worker, council, pipeline)
          - Inter-agent messaging (Write/Broadcast)
          - Selective waiting strategies
          - Complex error handling per pattern
          - Future extensibility without command bloat

  expert_location:
    question: Where to put expert files?
    options:
      - file: Agent files (plan, build, improve, question)
        location: .claude/agents/experts/<domain>/
      - file: Expertise YAML
        location: .claude/agents/experts/<domain>/expertise.yaml
      - file: Spec files from plan agents
        location: .claude/.cache/specs/<domain>/

patterns:
  expert_domain_4agent:
    structure: |
      .claude/agents/experts/<domain>/
      ├── expertise.yaml (400-600 lines target, 1000 max)
      ├── <domain>-plan-agent.md (yellow, Read/Glob/Grep/Write, academic-structured output)
      ├── <domain>-build-agent.md (green, Read/Write/Edit/Glob/Grep, +Bash for ops, practitioner-focused output)
      ├── <domain>-improve-agent.md (purple, all + Bash for git analysis, evidence-grounded output)
      └── <domain>-question-agent.md (cyan, Read/Glob/Grep, haiku model, concise-reference output)
    color_coding:
      plan: yellow (analysis, planning)
      build: green (creation, implementation)
      improve: purple (review, expertise evolution)
      question: cyan (meta, read-only Q&A)
    output_style_defaults:
      plan: academic-structured (rigorous specs, standard sections)
      build: practitioner-focused (action-first, code examples)
      improve: evidence-grounded (timestamped learnings, git-backed claims)
      question: concise-reference (scannable Q&A, tables/bullets)
    trade_offs:
      pros: [Plan→build→improve lifecycle with approval gates, Color-coded roles, Consistent output styles, Expertise evolves via git analysis]
      cons: [5 files vs 3 (old pattern), More complexity than standalone agents]

  expertise_path_protocol:
    purpose: Pass domain expertise to spawned agents without context bloat
    pattern: |
      All agents spawned via TeammateTool receive EXPERTISE_PATH parameter:
      EXPERTISE_PATH=/absolute/path/to/.claude/agents/experts/{domain}/expertise.yaml

      Agents read this file at runtime to:
      - Understand domain conventions
      - Apply relevant patterns
      - Reference historical learnings
      - Access decision trees and best practices
    rationale: |
      Expertise.yaml files are 400-600 lines (sometimes 1000+). Embedding in
      spawned agent prompts causes context bloat and token waste. File path
      reference is more efficient: agents load only what they need for their task.

      Lead agents read full expertise.yaml. Worker agents read task-specific
      sections. Question agents reference for answering domain queries.
    implementation: |
      1. When spawning agent via TeammateTool, include in prompt:
         EXPERTISE_PATH: {absolute_path}
      2. Agent reads file early in execution
      3. Agent extracts relevant patterns for current task
      4. Worker agents: focus on sections matching subtask
      5. Lead agents: full context to coordinate workers
    scale_benefits:
      - Supports large expertise files (1000 lines)
      - Keeps spawned agent prompts compact
      - Expertise evolves independently (agents pick up changes on spawn)
      - Multiple workers read same file without duplication
    timestamp: "[2026-02-02] Discovered in /do-teams orchestrator pattern"

  learning_separation_principle:
    purpose: Decouple swarm execution from expertise learning
    principle: |
      Swarm agents execute tasks. Improve agents learn from execution.
      These phases are separate and asynchronous.

      Execution Phase (live swarm):
      - Focus: Task execution only
      - Agents: Lead + workers perform work
      - Output: Files modified, results generated
      - No expertise updates

      Learning Phase (after swarm completes):
      - Focus: Extract patterns from execution
      - Agents: Domain improve-agent analyzes git history
      - Output: Expertise.yaml updates
      - User-triggered: /do "improve {domain} expertise"
    rationale: |
      Prevents race conditions: Multiple spawned agents cannot update expertise
      simultaneously. Keeps swarm execution focused and fast. Enables batch
      learning (analyze multiple swarm outputs together). Improves can fail
      without blocking successful execution.
    implementation: |
      1. Swarm execution via /do-teams command
         Result: Files committed/modified, task complete
      2. User (or future: scheduled automation) runs:
         /do "improve {domain} expertise"
      3. Improve agent:
         - Analyzes recent git history
         - Extracts patterns from swarm outputs
         - Updates expertise.yaml
         - Documents learnings with timestamps
    workflow_diagram: |
      User: /do-teams "complex task"
        ↓ swarm executes
      Result: Files modified, task complete
        ↓ separately:
      User: /do "improve {domain} expertise"
        ↓ improve agent analyzes git
      Result: Expertise.yaml updated with learnings
    trade_offs:
      pros: [No race conditions, Focused execution, Batch learning, Fail-safe]
      cons: [Extra step for user, Learning not automatic, Requires discipline]
    timestamp: "[2026-02-02] Pattern established in /do-teams design"

  flat_orchestration_architecture:
    constraint: "Phase 1 enforces flat architecture—no nested sub-swarms"
    reason: |
      Unknown whether TeammateTool supports nested spawning (spawning agents
      that themselves spawn teams). Flat architecture is safer, faster, and
      simpler to reason about.
    implementation: |
      /do-teams orchestrator spawns lead + workers (all flat).
      Workers do not spawn sub-teams.
      If nesting needed: orchestrator manually spawns agents sequentially.
    future_enhancement: |
      Once nested spawning is validated, can support:
      - Pipeline pattern (sequential handoffs)
      - Hierarchical coordination (manager agents spawn sub-teams)
      - Tree-based decomposition (hierarchical task breakdown)
    timestamp: "[2026-02-02] Constraint documented in do-teams.md (orchestration moved to command level)"

  skill_as_workflow_template:
    structure: |
      .claude/skills/<workflow>/SKILL.md (NO agent frontmatter)
      ---
      name: workflow-name
      description: Use when... Triggers on "keyword".
      ---
      # Workflow steps as documentation
    purpose: Guide /do orchestration (not executable agent)
    trade_offs:
      pros: [Eliminates nested subagent limitation, Easier to maintain than agent code]
      cons: [No programmatic workflow enforcement, /do centralized complexity]

  hook_coordination_via_temp_files:
    use_case: PreToolUse and PostToolUse need to share state (e.g., timing)
    pattern: |
      PreToolUse writes → PostToolUse reads → cleanup
      - .claude/data/temp/<session-id>-task-timing.txt
      - PostToolUse unlink() after read
    examples:
      - pre_tool_use_logger.py writes timing marker
      - orchestration_trace_logger.py reads, calculates latency, deletes file

  orchestration_observability:
    purpose: Capture Task tool invocations for meta-improvement
    implementation: |
      1. PostToolUse hook with Task matcher in settings.json
      2. Extract metadata (agent name, phase, domain, workflow_type)
      3. Calculate latency (via PreToolUse coordination)
      4. Append to .claude/.cache/orchestration-traces.jsonl
    trace_schema:
      timestamp: ISO 8601
      session_id: UUID
      agent_name: e.g., knowledge-build-agent
      phase: [plan, build, improve, question]
      domain: [knowledge, github, curriculum, ...]
      workflow_type: expert
      latency_ms: integer
      success: boolean
      total_tokens: integer

  agent_registry_pattern:
    purpose: Programmatic agent discovery for scale (10+ domains, 40+ agents)
    structure: |
      .claude/scripts/generate-agent-registry.py - Frontmatter scanner + indexer
      .claude/schemas/agent-registry.schema.json - Registry structure definition
      .claude/agent-registry.json - Auto-generated catalog (gitignored)
    generation_approach: |
      Scan .claude/agents/ recursively → extract frontmatter → infer capabilities →
      build indices (capability, model, tool, domain) → output JSON
    capability_inference:
      domain_based: "File path .../experts/{domain}/ → {domain}-domain capability tag"
      role_based: "Agent suffix *-plan-agent → planning, *-build-agent → implementation"
      description_based: "Keywords: research, review, orchestration, documentation-gathering"
    indices_generated:
      capabilityIndex: "Map: capability → [agent-ids]"
      modelIndex: "Map: model-tier → [agent-ids]"
      toolMatrix: "Map: tool-name → [agent-ids]"
      domains: "List: [{domain-id, domain-name, [agent-ids]}]"
    routing_use_cases: |
      - Cost-sensitive routing: Query → haiku agents (4× cheaper for Q&A)
      - Capability-aware routing: Task requiring Write → build agents only
      - Domain discovery: "Which agents can modify TypeScript?" → registry query
    update_timing:
      build_time: "Run script pre-deploy, commit registry (static, fast lookup)"
      runtime: "Parse frontmatter on-demand (dynamic, slower, always fresh)"
      hybrid: "Cache + invalidate on .claude/agents/ change (balanced)"
    scale_threshold: "10+ agents across multiple domains justifies registry automation"
    integration: "Registry enables /do command capability-based routing and agent selection"
    timestamp: "[2026-02-05] Implemented with generate-agent-registry.py + schema"

  template_driven_domain_scaffolding:
    purpose: Rapid expert domain creation with structural consistency (12th+ domain)
    structure: |
      .claude/agents/templates/
      ├── README.md - Quick-start guide + anti-patterns
      ├── base-agent.md - Minimal single-purpose agent
      ├── plan-agent.md, build-agent.md, improve-agent.md, question-agent.md
      └── expert-domain/ - Full 4-agent + expertise.yaml template set
          ├── {domain}-plan-agent.md
          ├── {domain}-build-agent.md
          ├── {domain}-improve-agent.md
          ├── {domain}-question-agent.md
          └── expertise.yaml (9-section schema template)
    workflow: |
      1. Copy expert-domain/ to .claude/agents/experts/{new-domain}/
      2. sed 's/{domain}/actual-domain/g' *.md (replace placeholders)
      3. Fill domain-specific content in expertise.yaml + agent instructions
      4. Update CLAUDE.md Experts table
      5. Run generate-agent-registry.py to include in discovery
    template_parameterization:
      placeholders: "{domain} (kebab-case), {Domain} (Title Case)"
      fixed_values: "tools, model, color, output-style per agent type (enforces 4-agent pattern)"
      variable_sections: "Expertise content, workflow customization, domain-specific operations"
    standardization_enforced:
      - Frontmatter structure (6 fields: name, description, tools, model, color, output-style)
      - Workflow sections (Understand → Analyze → Design → Create/Build → Save/Report)
      - expertise.yaml schema (9 sections with consistent format)
      - Agent naming ({domain}-{type}-agent pattern)
      - Cross-references (agents point to expertise.yaml as source of truth)
      - Registry compatibility (machine-readable metadata)
    time_savings:
      manual: "4-6 hours per domain, consistency drift over time"
      template: "30-60 minutes per domain, structural consistency guaranteed"
      roi_threshold: "3+ domains justifies template investment"
    emergence_note: |
      This book's 11 domains created through iterative standardization (commits 39e7904, 5002a1c),
      not upfront templating. Templates capture emerged 4-agent pattern for future domain creation.
    trade_offs:
      pros: [Fast scaffolding, Structural consistency, Onboarding-friendly, Registry-compatible]
      cons: [Upfront template maintenance, Less flexibility for specialized domains, May encourage premature domain creation]
    timestamp: "[2026-02-05] Implemented with .claude/agents/templates/ directory"

  coordinate_multi_agent_execution:
    when: Multiple agents need to execute with coordination/messaging vs simple delegation
    tool_selection: |
      Task tool (existing, sequential):
      - Sequential delegation (plan→build→approve→improve)
      - Simple spawn-and-wait model
      - No inter-agent messaging
      - /do command uses Task for expert delegation

      TeammateTool (new, parallel):
      - Parallel execution with messaging
      - Inter-agent communication (Write/Broadcast)
      - Selective waiting (join specific agents, not all)
      - Coordination patterns: lead-worker, council, pipeline
      - /do-teams command uses TeammateTool
    decision_criteria:
      - If agents work independently → Task (sequential)
      - If agents need messaging → TeammateTool (parallel)
      - If order matters → Task
      - If timing is flexible → TeammateTool
      - If one agent coordinates others → either (Task simpler if no messaging)
    implementation_patterns:
      lead_worker:
        use_when: One coordinator, N focused workers
        spawn: Lead agent + N worker agents
        coordination: Lead broadcasts work, workers write results to lead
        wait_strategy: Join lead only (workers may continue async)
      council:
        use_when: Multiple experts, equal standing, no single coordinator
        spawn: N expert agents (all equal)
        coordination: Orchestrator broadcasts question, experts write findings
        wait_strategy: Join all experts
      pipeline:
        use_when: Sequential with handoffs (future enhancement)
        spawn: Agents in sequence
        coordination: Agent N writes to Agent N+1
        wait_strategy: Join final agent
    timestamp: "[2026-02-02] Pattern extracted from /do-teams implementation"

  generate_agent_registry:
    when: Need programmatic agent discovery for routing logic (10+ agents across multiple domains)
    purpose: Auto-generate machine-readable agent catalog from frontmatter for capability-based routing
    implementation: |
      1. Create .claude/scripts/generate-agent-registry.py script
      2. Scan .claude/agents/ directory recursively for .md files
      3. Extract frontmatter (name, description, tools, model, color, output-style)
      4. Infer capabilities from agent metadata:
         - Domain capability from file path (experts/{domain}/ → {domain}-domain tag)
         - Role capability from agent suffix (*-plan-agent → planning, *-build-agent → implementation)
         - Description-based inference (research, review, orchestration, etc.)
      5. Build indices:
         - capabilityIndex: Map capabilities → agent IDs
         - modelIndex: Map model tiers → agent IDs
         - toolMatrix: Map tools → agent IDs
         - domains: Group agents by domain
      6. Output .claude/agent-registry.json (gitignored, auto-generated)
      7. Define schema in .claude/schemas/agent-registry.schema.json
    registry_structure: |
      {
        "generated": "ISO 8601 timestamp",
        "agents": [{agent metadata objects}],
        "domains": [{domain with agent lists}],
        "capabilityIndex": {"capability": ["agent-ids"]},
        "modelIndex": {"haiku|sonnet|opus": ["agent-ids"]},
        "toolMatrix": {"Tool": ["agent-ids"]}
      }
    routing_applications:
      cost_sensitive: Route queries to haiku agents for speed/cost optimization
      capability_aware: Route based on required tool access (Write, Bash, etc.)
      domain_discovery: "Which agents can help with GitHub operations?"
    update_strategies:
      build_time: Script runs before deployment, commit registry to repo (static lookup)
      runtime_query: Parse frontmatter on-demand (no pre-generated file, slower but fresh)
      hybrid_cache: Generate on first query, invalidate when .claude/agents/ changes
    good_fit:
      - 10+ agents across multiple domains
      - Programmatic routing logic (like /do command)
      - Cost-sensitive delegation (model tier selection)
      - Multi-agent orchestration systems requiring capability discovery
    poor_fit:
      - Small agent count (<5 agents)
      - Manual agent selection sufficient
      - Single-domain systems
    examples:
      - This book's 11-domain expert system (44+ agents) benefits from registry for /do routing
      - Cost routing: "How do I...?" → github-question-agent (haiku, 4× cheaper)
      - Capability routing: "Implement section" → knowledge-build-agent (has Write, WebSearch)
    timestamp: "[2026-02-05] Pattern implemented with generate-agent-registry.py + schema"

  scaffold_expert_domain_from_templates:
    when: Creating new expert domain (12th+ domain) and want consistency + speed
    purpose: Template-driven expert domain creation to maintain structural consistency
    implementation: |
      1. Maintain templates in .claude/agents/templates/:
         - base-agent.md (minimal single-purpose agent)
         - plan-agent.md, build-agent.md, improve-agent.md, question-agent.md
         - expert-domain/{domain}-{type}-agent.md (full 4-agent set)
         - expert-domain/expertise.yaml (9-section schema template)
      2. Copy expert-domain/ directory to .claude/agents/experts/{new-domain}/
      3. Replace {domain} placeholders with actual domain name:
         sed -i '' 's/{domain}/api-security/g' *.md (macOS)
      4. Fill domain-specific content:
         - Update expertise.yaml with domain patterns
         - Customize agent instructions and workflow steps
         - Document domain-specific operations
      5. Update CLAUDE.md Experts table
      6. Run generate-agent-registry.py to include in discovery index
    template_parameterization:
      frontmatter_placeholders:
        - "{domain}" → actual domain name
        - Fixed values: tools, model, color, output-style per agent type
      content_placeholders:
        - "{Domain}" → Title-cased domain name
        - "{domain}" → kebab-case domain name
        - Workflow sections remain consistent (Understand → Analyze → Design → Create → Save)
    standardization_benefits:
      - Frontmatter structure (name, description, tools, model, color)
      - Workflow sections (Understand → Apply → Formulate → Report)
      - expertise.yaml schema (9 sections: overview, core_implementation, key_operations, decision_trees, patterns, best_practices, known_issues, potential_enhancements, stability)
      - Cross-references between agents
      - File naming conventions
      - Registry compatibility (machine-readable frontmatter)
    time_investment:
      manual_authoring: "4-6 hours per domain, variable consistency (drift over time)"
      template_generation: "30-60 minutes per domain, high consistency (templates enforce structure)"
    good_fit:
      - Adding 3+ new domains (upfront template investment pays off)
      - Onboarding new contributors (templates provide scaffolding)
      - Maintaining consistency across large expert systems (11+ domains)
    poor_fit:
      - First 2-3 domains (establishing patterns organically)
      - Highly specialized domains requiring custom structure
      - One-off expert agents not part of domain system
    examples:
      - This book's 11 expert domains created through iterative standardization (not upfront templating)
      - Templates capture emerged pattern for future (12th+) domain creation
      - Template README.md provides quick-start instructions and anti-patterns
    timestamp: "[2026-02-05] Pattern implemented with .claude/agents/templates/ directory structure"

best_practices:
  organization:
    - Agents in .claude/agents/, commands in .claude/commands/
    - Expert domains: agents/experts/<domain>/ (4-agent + expertise.yaml)
    - Orchestrator agents: .claude/agents/<name>-orchestrator-agent.md (paired with command)
    - Skills: .claude/skills/ as workflow templates (NOT agents)
    - Specs: .claude/.cache/specs/ (gitignored ephemeral)
    - Expertise.yaml: 400-600 lines target, 1000 hard limit
    - Output styles: .claude/output-styles/ as reusable formatting conventions

  commands:
    - Naming: category:command pattern (/book:toc)
    - Frontmatter: description (required), argument-hint, allowed-tools
    - Use allowed-tools to restrict capabilities per command
    - CRITICAL: Never use colons in frontmatter string values (breaks YAML parsing)
    - For complex workflows: pair command with orchestrator agent (not 4-agent pattern)

  orchestrator_agents:
    - DEPRECATED PATTERN: Originally designed separate orchestrator agents for multi-pattern coordination
    - ARCHITECTURE CHANGE [2026-02-02]: Orchestration must happen at command level, not in subagents
    - Reason: Subagents spawned via Task tool cannot use Task/TeammateTool to spawn nested agents
    - New pattern: Command file contains ALL orchestration logic (see /do and /do-teams as examples)
    - Supports multiple coordination patterns (lead-worker, council, pipeline)
    - Use TeammateTool for parallel coordination with messaging
    - Do NOT include improve phase (learning handled separately per learning_separation_principle)
    - Pass EXPERTISE_PATH to spawned agents (expertise_path_protocol pattern)

  expert_domains:
    - Standardized color coding (yellow/green/purple/cyan)
    - Standardized output styles (concise-reference/academic-structured/practitioner-focused/evidence-grounded)
    - Question agents: haiku model, read-only tools, concise-reference output
    - Plan agents: academic-structured output for rigorous specs
    - Build agents: practitioner-focused output for action-first guidance
    - Improve agents: Bash for git history analysis, evidence-grounded output with timestamps
    - Absorb standalone agents >300 lines into expert domains
    - CRITICAL: Never use colons in description field (breaks agent discovery)
    - Use templates for 3+ new domains (30-60min vs 4-6hr manual authoring)
    - Run generate-agent-registry.py after adding domains for discovery index

  coordination:
    - Use Task tool for sequential delegation (plan→build→improve)
    - Use TeammateTool for parallel coordination with messaging
    - Pass expertise via EXPERTISE_PATH (file reference, not embedding)
    - Implement learning_separation_principle: execution and improvement are separate phases
    - For swarms: orchestrator spawns all agents flat (no nesting Phase 1)
    - Document coordination pattern (lead-worker, council, pipeline) in orchestrator

  swarm_operational_practices:
    - Shutdown ceremony is optional: quick research swarms can skip explicit shutdown (5min timeout saves 3-4 turns)
    - Full shutdown ceremony for production swarms: SendMessage with request/shutdown subtype, wait for approval
    - Instruct teammates to send plain-text results only (suppress JSON status messages in prompts)
    - Idle notifications are JSON and system-generated: ignore them, wait for plain-text results
    - Expected timing: spawn to first result ~30s, all parallel results ~1-2min, shutdown ceremony ~30s overhead
    - No progress visibility: instruct teammates to send interim updates if long-running tasks
    - Validation levels in worker prompts: Level 1 (syntax only), Level 2 (tests + types), Level 3 (full suite + manual)
    - Forbidden patterns: negative constraints, meta-commentary, vague instructions, unbounded scope
    - Role-based tool access: specify allowed tools explicitly to prevent confusion
    - timestamp: "[2026-02-02] Tactical patterns from initial /do-teams usage and refinement (commit 75a4962)"

  hooks:
    - uv shebang for Python dependencies
    - Configure in settings.json by event type
    - Exit 0 (allow), 2 (block)
    - Matcher for tool-specific hooks (reduces overhead)
    - Temp files in .claude/data/temp/ for cross-hook coordination
    - Cleanup temp files after read (unlink)

  settings:
    - settings.json: project-wide (committed)
    - settings.local.json: local overrides (gitignored)
    - Valid JSON (no trailing commas)

  observability:
    - JSONL for append-only trace logs
    - Extract structured metadata from agent names
    - Store traces in .claude/.cache/ (gitignored)

known_issues:
  - issue: No automated validation of command frontmatter
    workaround: Manual review during command creation
    status: open

  - issue: Spec files in .claude/.cache/specs/ accumulate
    workaround: Manual cleanup (gitignored, non-critical)
    status: open

  - issue: Hook errors not always visible
    workaround: Explicit logging in hooks
    status: open

  - issue: Colons in frontmatter string values break YAML parsing
    impact: Agents/commands with colons in description field fail discovery silently
    resolution: |
      Fix b6a2b47 removed colons from 38 agent descriptions across 12 domains.
      Pattern changed from 'Expects: SPEC' to 'Expects SPEC'.
      Root cause: Claude Code YAML parser treats unquoted colons as key-value separators.
    prevention: Lint rule or validation check needed
    status: resolved [2026-01-17]

  - issue: Nested subagent limitation (coordinators couldn't spawn experts)
    resolution: Flat orchestration - /do directly spawns expert agents (commit 353d576)
    status: resolved

  - issue: Old 3-file expert pattern mixed location concerns
    resolution: 4-agent pattern in agents/experts/ (all 12 domains migrated)
    status: resolved

potential_enhancements:
  - Automated frontmatter validation for commands (low effort)
  - Command discovery interface - list all commands (low effort)
  - Spec file cleanup automation (low effort)
  - Hook debugging mode for visible errors (medium effort)
  - Orchestration trace aggregation tool for latency stats (low effort)
  - Temp file orphan cleanup on SessionStart (low effort)
  - Research nested TeammateTool spawning (medium effort, unblocks pipeline and hierarchical patterns)
  - Orchestrator agent templates for lead-worker, council, pipeline patterns (low effort, tooling)
  - Swarm execution visualization (medium effort, observability enhancement)
  - EXPERTISE_PATH hot-loading for multi-domain swarms (low effort, optional optimization)
  - Integrate agent-registry.json into /do command routing logic (low effort, enables capability-based agent selection)
  - Template generator CLI tool (medium effort, automate sed placeholder replacement)
  - Registry-powered agent search command (low effort, "which agents can modify X?")
  - Template validation checks (medium effort, ensure templates maintain structural consistency)

stability:
  convergence_indicators:
    insight_rate_trend: stable
    contradiction_count: 0
    new_patterns_added_this_cycle: 2
    patterns_updated_this_cycle: 0
    decision_trees_added_this_cycle: 0
    last_reviewed: 2026-02-05
    utility_ratio: 1.0
    notes: |
      Cycle 2026-02-05: Tooling and scaffolding patterns for agent domain scaling.

      New Patterns Added:
      1. agent_registry_pattern (key_operations + patterns sections)
         - Programmatic agent discovery via frontmatter scanning
         - Capability-based routing (model tier, tool access, domain)
         - Auto-generated indices (capability, model, tool, domain)
         - Scale threshold: 10+ agents across multiple domains
         - Implementation: .claude/scripts/generate-agent-registry.py + schema

      2. template_driven_domain_scaffolding (key_operations + patterns sections)
         - Rapid expert domain creation (30-60min vs 4-6hr manual)
         - Structural consistency enforcement via templates
         - 4-agent pattern standardization (plan/build/improve/question)
         - expertise.yaml schema template (9 sections)
         - Implementation: .claude/agents/templates/ directory

      Pattern Classification:
      Both patterns are FOUNDATIONAL (preserve indefinitely):
      - Agent registry enables discovery layer for expert systems at scale
      - Templates capture emerged 4-agent pattern for future domain creation
      - Both support systems with 10+ domains, 40+ agents
      - Cross-domain applicability (any multi-agent system needing discovery/scaffolding)

      Files Added (untracked, new implementations):
      - .claude/scripts/generate-agent-registry.py (217 lines)
      - .claude/schemas/agent-registry.schema.json (133 lines)
      - .claude/agents/templates/ directory (8 files, ~2700 lines total)
        - README.md, base-agent.md, plan/build/improve/question-agent.md
        - expert-domain/ subdirectory with full 4-agent template set

      Best Practices Updated:
      - expert_domains: Added template usage guidance + registry generation reminder
      - potential_enhancements: Added 4 registry/template related enhancements

      File Health:
      - Before: 596 lines
      - After: 783 lines (+187 lines)
      - Still below 900 warning threshold (117 lines of headroom)
      - Largest additions: 2 key_operations entries, 2 patterns entries

      Domain Stability:
      Medium-high. This cycle adds tooling patterns for scale management (not core
      architectural changes). Registry and templates emerged from need to manage 11
      domains efficiently. Patterns are retrospective documentation of implementations
      already created today (2026-02-05).

      Insight Rate: Stable (2 foundational patterns, both tooling/operational, not
      conceptual). Previous cycle added swarm tactical refinements. Cycle before that
      added major architectural patterns. Trend suggests core architecture stable,
      now adding operational tooling.

      Previous Cycle (2026-02-02b): Tactical swarm refinements (+12 lines).
      Previous Cycle (2026-02-02a): Major architectural patterns (+195 lines).
